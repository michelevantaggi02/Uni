

Data una funzione razionale $f: R^2 \to R$ che sia $f = \frac pq$ con $p$ e $q$ polinomi.

Dall'analisi matematica sappiamo che $f$ è definita e differenziabile per $q \neq 0$ (assumendo che $p$ e $q$ siano primi).

Ci sono due tipi di errori nella valutazione di $f$ con i valori in virgola mobile

## Errore Inerente

Non valutiamo $f(x)$ ma valutiamo $f(\tilde x)$ dove $\tilde x = fl(x)$ [[2. Error Analysis#^59010a|funzione approssimata]]

$$\varepsilon_{IN} = \frac{f(\tilde x) -f(x)}{f(x)}, \quad f(x) \neq 0$$

Se l'errore inerente è relativamente piccolo possiamo dire che il problema è __ben condizionato__, altrimenti che è __mal condizionato__.

L'errore inerente può essere definito anche per funzioni __non razionali__

## Errore Algoritmico

Non si valuta $f(\tilde x)$ ma si valuta $\tilde f (\tilde x)$

$$\varepsilon_{ALG} = \frac{\tilde f (\tilde x ) - f (\tilde x )}{f(\tilde x )}, \quad f(\tilde x ) \neq 0$$

Se l'errore algoritmico è relativamente piccolo possiamo dire che l'algoritmo $f$ è __numericamente stabile__, altrimenti che è __numericamente instabile__.

L'errore algoritmico può essere definito anche per le funzioni elementari che vengono trattate come operazioni.

## Errore Totale

$$\varepsilon_{TOT} = \frac {\tilde f(\tilde x ) - f(x)}{f(x)}, \quad f(x) \neq 0$$
Dà una misura genuina dell'errore nella valutazione.

La situazione ideale è $|\varepsilon_{tot}| < u$, ma in pratica è sufficiente $|\varepsilon_{tot}| < Mu$ con $M$ costante.

```ad-important
title: Teorema

Dato $x \in R^n \backslash \{0\}$ e $f : R^n \to R$ razionale con $f(x) \neq 0$, dove $\tilde x = fl(x)$, allora

$$\varepsilon_{TOT} = \varepsilon_{IN} + \varepsilon_{ALG} + \varepsilon_{IN}\varepsilon_{ALG}$$

```

Se $\varepsilon_{IN}$ e $\varepsilon_{ALG}$ tendono a 0 con $u \to 0$, abbiamo
$$\varepsilon_{TOT} = \varepsilon_{IN} + \varepsilon_{ALG} + o(u) = \varepsilon_{IN} + \varepsilon_{ALG}$$

``````ad-example
collapse: open

Sia $\tilde x = fl(x) = x(1 + \varepsilon_1), \quad |\varepsilon_1| < u$ ottenuto come
$$\frac {\tilde x - x}x = \varepsilon_1 \iff \tilde x - x = x\varepsilon_1 \iff \tilde x = x(1 + \varepsilon_1)$$

Abbiamo per $x \neq 0$:

$$\varepsilon_{IN} = \frac {\tilde x^2 - x^2}{x^2} = \frac{[x(1+\varepsilon_1)]^2 -  x ^2}{x^2} = \frac{x^2(1 + \varepsilon_1)^2 - x^2}{x^2} = \frac{x^2[(1 + \varepsilon_1)^2 - 1]}{x^2} = $$
$$ = 2 \varepsilon + \varepsilon^2$$

Dato che a noi interessa quello che succede con $u \to 0$, possiamo  considerare solo i termini più lenti.

$$ |\varepsilon_{IN}| = |2\varepsilon + \varepsilon^2| \leq 2|\varepsilon| + |\varepsilon^2| < 2u + u^2 = 2u, \quad u \to 0$$

è [[4. Problemi Ben Posti#^3243f8|ben condizionato]].

__Esiste un'altra formula__ per calcolare l'errore inerente:

$$\varepsilon_{IN} = \frac x{f(x)}f'(\xi)\varepsilon_x$$

Dove $\varepsilon_x = \varepsilon_1$ è la rappresentazione dell'errore in $x$ se $f \in C^2(conv(x, \tilde x))$ allora:
$$\varepsilon_{IN} = \frac x{f(x)} f'(x)\varepsilon_x + o(u) = \frac {x \cdot 2x}{x^2}\varepsilon_x = 2\varepsilon_x$$

```ad-done
title: Dimostrazione

Uso il teorema di Lagrange applicato alla funzione in un intorno di 0

$$f(x) = f(0) + f'(0)x + o(x) \doteq f(0) + f'(0)x$$


```

```ad-important

Il termine $\varepsilon_{IN} = \frac{f(\tilde x) - f(x)}{f(x)} \doteq \frac x{f(x)}f'(x)\varepsilon_x$ si chiama __fattore di amplificazione__ e misura l'amplificazione dell'errore

```


``````

^f13037

