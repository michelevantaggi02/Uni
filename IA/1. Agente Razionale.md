Un agente che di solito fa la cosa giusta

```ad-question
title: Ma come si decide qual √® la cosa giusta?


```

- Misura di prestazione
- Conoscenza dell'ambiente
- Azioni che pu√≤ eseguire
- Sequenza percettiva

```ad-important
title: Agente razionale


Per ogni possibile sequenza di percezioni, un agente razionale dovrebbe __scegliere un'azione che massimizzi il valore atteso__ della sua misura di prestazione, date le informazioni __fornite dalla sequenza percettiva__ e da ogni ulteriore conoscenza dell'agente
```

```ad-example
title: Aspirapolvere

![[aspirapolvere.png]]

Pulisce la stanza se √® sporca, altrimenti va nell'altra stanza.

3 azioni:
- Vai nella stanza a destra
- Vai nella stanza a sinistra
- Aspira la sporcizia

~~~ad-question
title: √® razionale?

Non possiamo rispondere senza un criterio

__Misura di prestazione__:
	$m_1$ +1 per ogni stanza pulita
~~~
```

# Rappresentazione Degli Stati

![[RapprStati.png]]

Noi lavoreremo sugli stati __atomici__

# Search Problem

| alg | completezza | ottimalit√† |             costo spazio             |             costo tempo              |
|:---:|:-----------:|:----------:|:------------------------------------:|:------------------------------------:|
| BFS |     si      |     si     |               $O(b^m)$               |               $O(b^m)$               |
| UCS |     si      |     si     | $O(b^{\frac {C*}{\varepsilon} + 1})$ | $O(b^{\frac {C*}{\varepsilon} + 1})$ |
| DFS |     no      |     no     |               $O(bm)$                |               $O(b^m)$               |
| DLS |     no      |     no     |               $O(bl)$               |               $O(b^l)$                |
| IDS |     si      |     si     |               $O(bd)$                | $O(b^d)$                                     |

- state space ($S$)
- initial state ($s_i \in S$)
- goal_test($S$)$\to$ true | false
- actions($S$) = $\{a_1,...,a_n\}$
- results($S,a$)$\to S'$
- path_cost($S\substack {a\\\to} ... \substack {a_n \\ \to}S_n$) = $n$
  step_cost($S,a,S'$) = $n$

Se ho step_cost posso calcolare path_cost

```ad-example
title: Romaniaüá∑üá¥

![[mappaRomania.png]]

Se voglio andare da __Arad__ a __Bucarest__ basta rappresentare le citt√† come stati e le azioni come lo spostarsi da una citt√† ad un'altra

- state space: tutte le citt√†
- initial state: Arad
- goal_test(S): is Bucarest?
- actions(S): {vai a citt√† #}, # √® una citt√† raggiungibile
- results(S,a) = citt√† di arrivo
- step_cost(S,a,S') = costo sulla mappa


```

## Best-first-search

	function BEST-FIRST-SEARCH(problem, f ) returns a solution node or failure
		node ‚Üê NODE(STATE=problem.INITIAL)
		frontier ‚Üê a priority queue ordered by f , with node as an element
		reached ‚Üê a lookup table, with one entry with key problem.INITIAL and value node
		while not IS-EMPTY(frontier ) do
			node ‚Üê POP(frontier )
			if problem.IS-GOAL(node.STATE) then return node
			for each child in EXPAND(problem, node) do
				s ‚Üê child .STATE
				if s is not in reached or child .PATH-COST < reached [s].PATH-COST then
					reached [s] ‚Üê child
					add child to frontier
		return failure


	function EXPAND(problem, node) yields nodes
		s ‚Üê node.STATE
		for each action in problem.ACTIONS(s) do
			s‚Ä≤ ‚Üê problem.RESULT(s, action)
			cost ‚Üê node.PATH-COST + problem.ACTION-COST(s, action, s‚Ä≤)
			yield NODE(STATE=s‚Ä≤, PARENT=node, ACTION=action, PATH-COST=cost)

## Breadth-first-search (BFS)

Riguardare anche [[a1. Grafi#Breadth First Search]]

	function BREADTH-FIRST-SEARCH(problem) returns a solution node or failure
		node ‚Üê NODE(problem.INITIAL)
		if problem.GOAL-TEST(node.STATE) then return node
		frontier ‚Üê a FIFO queue, with node as an element
		reached ‚Üê {problem.INITIAL}
		while not IS-EMPTY(frontier ) do
			node ‚Üê POP(frontier )
			for each child in EXPAND(problem, node) do
				s ‚Üê child .STATE
				if problem.GOAL-TEST(s) then return child
				if s is not in reached then
					add s to reached
					add child to frontier
		return failure

### Propriet√†

Processa tutti i nodi pi√π superficiali, data la profondit√† della soluzione pi√π superficiale come $s$, il tempo e lo spazio di ricerca sono di $O(b^s)$.

- $s$ √® finito se esiste una soluzione, quindi √® completo.
- √® __ottimale__ solo se __i costi sono tutti 1__

## Uniform-cost-search (UCS)

	function UNIFORM-COST-SEARCH(problem) returns a solution or failure
		node <- NODE(problem.INITIAL)
		frontier <- priority queue ordered by PATH-COST, with node as only element
		explored <- empty set
		while NOT IS-EMPTY(frontier) do
			node <- POP(frontier) //chooses the lowest-cost node
			if problem.GOAL-TEST(node.state) then return node
			add node.STATE to explored
			for each action in problem.ACTIONS(node.STATE) do
				child <- CHILD-NODE(problem, node, action)
				if child.STATE is not in explored or frontier then
					add child to frontier
				else if child.STATE is in frontier with higher PATH-COST then
					replace frontier node with child
			
		return failure

### Propriet√†

Processa tutti i nodi con costo minore della soluzione con costo minore, se quella soluzione costa $C^*$ e gli archi hanno costo di almeno $\varepsilon$, allora la "profondit√† effettiva" √® di $C^* / \varepsilon$ e il tempo e lo spazio di esecuzione sono quindi $O(b^{C^* / \varepsilon})$

- Assumendo che la soluzione abbia costo finito e che il costo minimo di un arco sia positivo, allora √® completo
- √® ottimale (Prova tramite $A^*$)

## Depth-first-search (DFS)

Riguarda anche [[a1. Grafi#Visita in Profondit√† (DFS-visit)]]

	function DEPTH-FIRST-SEARCH(problem) returns a solution or failure
		node <- NODE(problem.INITIAL)
		frontier <- LIFO queue with node as element
		explored <-  empty set
		while NOT IS-EMPTY(frontier) do
			node <- POP(frontier)
			if problem.GOAL-TEST(node.state) then return node
			add node.state to explored
			for each child in EXPAND(problem, node) do
				if child.state not in explored and child not in frontier then
					add child to frontier
		return none

### Propriet√†

Espande alcuni nodi a sinistra dell'albero (potrebbe processare tutto l'albero), se $m$ √® finito, impiega in tempo $O(b^m)$ e in spazio $O(bm)$

- √® completo solo se preveniamo i cicli, quindi $m$ potrebbe essere finito
- __Non √® ottimale__, trova solamente la soluzione "pi√π a sinistra",

## Tree-search

	function TREE-SEARCH(problem):
	frontier = {[initial]}
	loop:
		if frontier is empty: return fail
		path = remove_choice(frontier)
		s = path.end
		if s is a goal: return path
		for a in actions:
		add [path + a to result(S, G)] to frontier

## Propriet√† Degli Algoritmi Di Ricerca

- Completo: √® garantito che trovi una soluzione se questa esiste?
- Ottimo: √® garantito che trovi il percorso di costo minore?
- Complessit√† di tempo
- Complessit√† spaziale

![[0. Intelligent Agent#^3ea88e]]

- pi√π √® grande il branching factor (b) pi√π √® complessa la ricerca
- _m_ √® la profondit√† massima
- Le soluzioni si possono trovare a diverse profondit√†
- numero di nodi nell'intero albero:$$1+ b + b^2 + ... + b^m = O(b^m)$$

![[prop_algoritmi_ricerca.png|center]]

``````ad-example
title: Ottimalit√† BFS

\# passi o costo se $\text{step\_cost(a)} = \text{step\_cost(a')} \forall a,a' \in \text{ACTIONS}$

$$O(b^n) \text{ spazio}$$
$$O(b^n) \text{ tempo}$$

```ad-question
title: Completezza

si perch√© se esiste soluzione l'albero ha costo finito

```

``````

```ad-example
title: Ottimalit√† UCS

- Completezza: si
- Ottimalit√†: si
$$O(b^{\frac {C*}{\varepsilon} + 1}) \text{ spazio e tempo}$$

```

```ad-example
title: Ottimalit√† DFS

- Completezza: no
- Ottimalit√†: no

$$O(bm) \text{ spazio}$$
$$O(b^m) \text{ tempo}$$
```

## Iterative Deepening

L'idea √® di utilizzare la DFS per il suo costo in spazio, con i vantaggi di tempo della BFS.

Eseguo la DFS con un limite sulla profondit√† che aumenta ad ogni iterazione.

```ad-question
title: Non √® uno spreco eseguire tante volte gli stessi passi?

Si, ma la maggior parte dei calcoli va fatta nel livello pi√π basso (o il limite in questo caso), quindi non √® cos√¨ male

```

	function ITERATIVE-DEEPENING-SEARCH(problem) returns a solution or failure
		for depth = 0 to INFINITE do
			result <- DEPTH-LIMITED-SEARCH(problem, depth)
			if result is not cutoff then
				return result

	function DEPTH-LIMITED-SEARCH(problem, l) return a node or failure or cutoff
		frontier <- STACK with NODE(problem.INITIAL) as element
		result <- failure
		while not IS-EMPTY(frontier) do
			node <- POP(frontier)
			if problem.GOAL-TEST(node.state) then return node
			if DEPTH(node) > l then
				result <- cutoff
			else if not IS-CYCLE(node) do
				for each child in EXPAND(problem, node) do
					add child to frontier
		return result

# Ricerca Informata (Euristica)

```ad-important
title: Funzione euristica

funzione arbitraria problem specific, stima il costo per raggiungere il goal dallo stato.
- $h(\text{goal}) = 0$
- $h(s) > 0$

√® calcolabile in tempi ragionevoli

```


```ad-important
title: Greedy  Best First

[[#Best-first-search]] con coda di priorit√† organizzata secondo $h$

```


```ad-important
title: Algoritmo $A^*$

Combina:

- Costo $g(n) = \text{PATH\_COST}(n)$ per raggiungere $n$ dallo stato iniziale
- Euristica $h(n)$ stima per raggiungere il GOAL a partire da $n$
$$f(n) = g(n) + h(n)$$

Se $h$ √® __ammissibile e consistente__ allora $A^*$ √® __ottimale__

```

![[comp_algoritmi.png]]

Con $A^*$ abbiamo trovato lo stesso percorso espandendo molti meno nodi.

A parit√† di costo bisogna avere "fortuna", dato che i nodi vengono poi espansi in ordine

```ad-fail
title: Problema

![[sovrastima.png]]

Abbiamo sovrastimato il costo di $A$ impedendogli di avere la possibilit√† di essere espanso

```

## Euristica Ammissibile

Un'euristica $h$ √® ammissibile se $$h(n) \leq h^*(n)$$

dove $h^*(n)$ √® il vero costo per il goal pi√π vicino.

Trovare un'euristica ammissibile √® il lavoro pi√π grande nell'usare $A^*$ in pratica.

```ad-check
title: $h$ ammissibile e $A^*$ ottimale

Se $h$ √® ammissibile $\implies$ $A^*$ √® ottimale rispetto al costo.

Per assurdo $h$ ammissibile e $\exists$ percorso meno costoso di quello trovato da $A^*$

- $C^*$ costo cammino ottimo
- $n$ nodo sul cammmino ottimo che non √® stato espanso, $f(n) > C^*$
- $g^*(n)$ costo ottimo del cammmino fino ad $n$
- $h^*(n)$ costo ottimo da $n$ fino al goal


$$f(n) = g(n) + h(n) = g^*(n) + h(n) \leq g^*(n) + h^* (n) = C^* \implies f(n) \leq C^*$$

L'ipotesi di $h$ ammissibile e $A^*$ non ottimale √® assurda

```

### Consistenza

$h(n)$ √® __consistente__ se $\forall$ nodo $n, n' : n' \in \text{ACTIONS}(n)$ allora $h(n) \leq h(n') + c(n, a , n')$

Se $h$ √® consistente allora √® anche ammissibile, ma non il contrario

![[RomaniaAstar.png]]

## Contorni Di $A^*$

$A^*$ √® ottimamente efficiente, ma non ci interessa

![[contorni_Astar.png|center]]

Rispetto alla [[#Uniform-cost-search (UCS)]] lo spazio di ricerca di f$A^*$ √® completamente diverso. Se $h$ √® fatta bene, $A^*$ controlla nodi di soluzione sempre crescente e i contorni saranno incentrati al percorso ottimale.

### Propriet√† Di $A^*$

- Completezza, a meno che non ci siano infiniti nodi di costo maggiore
- Ottimale, nessun altro algoritmo euristico ne espande di meno
- Tempo esponenziale nel caso peggiore
- Spazio esponenziale nel caso peggiore

### Ricerca $A^*$ Pesata

_A* ha molte qualit√† ma espande troppi nodi_ (quindi occupa tanta memoria), quindi il compromesso giusto √® quello di __determinare una soluzione sub-ottima__, in A* un euristica __inammissibile √® utilizzabile__ se la soluzione √® abbastanza ottima.

Il problema di espandere troppi nodi pu√≤ essere rilevante se lo spazio in cui lavora √® molto grande In **A* pesata** la funzione f √® uguale alla solita ma utilizzia in pi√π un valore W che pesa l'euristica, cio√® $$f(n) = g(n) + W \times h(n)$$

_Quando si utilizza A* con un'euristica consistente_, sebbene possa espandere un gran numero di nodi durante la ricerca, l'efficienza complessiva √® mantenuta grazie alla capacit√† dell'euristica di _"potare" (eliminare - pruning)_ rami dell'albero di ricerca che non sono necessari per trovare la soluzione ottima. Questa √® una delle caratteristiche chiave di A* che lo rende un algoritmo di ricerca efficiente quando √® ben bilanciato in quanto i percorsi che va ad espandere sono in qualche modo correlati al percorso ottimo. √à molto pi√π __facile trovare__ euristica __buone ma non ammissibili__ che euristiche ammissibili.

## $A^*$ Ad Approfondimento Iterativo (IDA*)

- Elimina le limitazioni di memoria di $A^*$ senza sacrificare l'ottimalit√† della soluzione
- Ogni iterazione dell'algoritmo √® una [[#Depth-first-search (DFS)]] che tiene traccia del costo $f(n) = g(n) + h(n)$ di ogni nodo generato
- Quando il costo di nodo eccede la soglia per quell'iterazione, il suo percorso viene tagliato fuori, e la ricerca torna indietro
- La soglia del costo viene inizializzata all'euristica stimata dello stato iniziale
- Ad ogni iterazione la soglia viene aumentata del costo totale del nodo con costo pi√π basso che √® stato rimosso nella precedente iterazione.
- L'algoritmo termina quando viene raggiunto un goal il cui costo totale non eccede la soglia attuale.

### Vantaggi

- Se l'__euristica__ √® __ammissibile__, IDA* trova la __soluzione ottimale__
- I requisiti in memoria sono lineari rispetto alla profondit√† massima di ricerca

### Difetti

- Non √® una ricerca best-first a tutti gli effetti
- Si espandono gli stessi nodi, spesso sono quelli pi√π vicini alla radice che sono di meno e hanno un costo che possiamo sopportare
- Quando ricomincia scarta tutte le informazioni tranne la prossima soglia

## Recursive-best-first (RBFS)

	function RECURSIVE-BEST-FIRST(problem) returns a solution or failure
		solution, fvalue <- RBFS(problem, NODE(problem.INITIAL), INFINITE)
		return solution

	function RBFS(problem, node, f_limit) returns solution or failure and a new limit
		if problem.GOAL-TEST(node.STATE) then return node
		successors <- LIST(EXPAND(node))
		if IS-EMPTY(successors) then return failure, INFINITE
		for each s in successors do //aggiorno f con il valore della ricerca precedente
			s.f <- max(s.PATH-COST + h(s), node.f) 
		while true do
			best <- nodo in successors con f-value minore
			if best.f > f_limit then return failure, best.f
			alternative <- secondo f-value tra i successori
			result, best.f <- RBFS(problem, best, min(f_limit, alternative))
			if result is not failure then return result, best.f

L'idea √® quella di avere tutti i vantaggi della [[#Breadth-first-search (BFS)]], con un'utilizzo lineare della memoria:

- Non mantiene aperti tutti i rami (Come fa A*),ma usa una variabile per ricordare la seconda scelta migliore
- Quando la prima scelta fallisce (diventa peggiore della seconda), l'algoritmo sa dove andare
- Cancella il ramo che fallisce, ricordandosi il valore migliore di $f$ per quel ramo


### Propriet√†

- Come A* √® ottimale se $h(n)$ √® ammissibile
- La complessit√† in tempo √® difficile da caratterizzare
	- dipende dall'accuratezza di $h(n)$ e quanto spesso cambia il percorso migliore
	- Pu√≤ finire a fare avanti e indietro con i cambiamenti di ramo
- La complessit√† in spazio √®  $O(bd)$ (altro estremo di A*, usa troppa poca memoria)

Troppa poca memoria vuol dire che deve rigenerare troppi nodi ad ogni iterazione, anche se c'√® della memoria disponibile questa non pu√≤ essere usata dall'algoritmo

## SMA*

Esiste la possibilit√† di avere un A* memory-bounded (MA*), una sua versione semplificata, chiamata SMA* ha queste caratteristiche:

- Come A* espande il child migliore, ma ha un limite in memoria
- Quando la memoria √® piena deve cancellare un nodo, quello con il valore f-value pi√π alto
- Come la RBFS mantiene il valore del nodo cancellato e il suo nodo padre

- Completo se c'√® abbastanza memoria da contenere la soluzione
- Ottimale se viene raggiunta la soluzione ottima