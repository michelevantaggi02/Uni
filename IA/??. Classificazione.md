Data una collezione di record (training set) dove ogni record è caratterizzato da una tupla $(x,y)$, dove $x$ è l'insieme di attributi e $y$ è l'etichetta della classe:

- $x$: attributo, variabile indipendente, input
- $y$: classe, risposta, variabile dipendente, output

L'obiettivo è di imparare un modello che mappa ogni insieme di attributi $x$ in una delle classi $y$.

# Tecniche Di Classificazione

Classificazioni base:

- Metodi basati sugli __alberi di decisione__
- Metodi basati sulle __regole__
- __Nearest-Neighbor__
- __Neural Networks__
- __Deep Learning__
- Reti __Naive Bayes__ e __Bayesan Belief__
- __Support Vector Machines__

Classificazioni 


# K-Nearest Neighbors

Funziona molto bene con i dataset piccoli, ed è necessario quando i dataset che cambiano spesso.

è quindi molto utile quando si ha bisogno di riallenare tutto ogni volta, perché questo non lo fa.

# Naive Bayes

Trasformano i problemi in problemi di calcolo di probabilità

```ad-teorema
title: Teorema di bayes

Si basa sulla probabilità condizionale.

La probabilità che un evento $Y$ accada, se è al momento presente un evento $X$ è data da $P(X,Y)$ probabilità che accadano entrambi$$P(Y|X) = \frac{P(X,Y)}{P(X)}$$

Il teorema dice che si può calcolare tramite $$P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}$$

Quindi conoscendo l'inverso (ovvero la probabilità che X accada se abbiamo Y), possiamo trovare quello che cerchiamo

```
